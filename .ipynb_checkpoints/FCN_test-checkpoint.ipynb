{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCN\n",
    "This notebook contains a test CNN in pytorch, to get familiar with this developping environment. It also acts as a template for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17d94ff5bd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os,sys\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "#seed for reproducible results\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - np.min(img)\n",
    "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "    return rimg\n",
    "\n",
    "# Concatenate an image and its groundtruth\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = np.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def uniform(a,b):\n",
    "    return(a+(b-a)*random())\n",
    "\n",
    "def img_rnd_crop(im, w, h, i = -1, j = -1):\n",
    "    is_2d = len(im.shape) < 3\n",
    "    imgwidth = im.shape[len(im.shape)-2]\n",
    "    imgheight = im.shape[len(im.shape)-1]\n",
    "    if (i == -1 and j == -1):\n",
    "        i = int(uniform(0, imgwidth-w-1))\n",
    "        j = int(uniform(0, imgheight-h-1))\n",
    "    if is_2d:\n",
    "        im_patch = im[i:i+w, j:j+h]\n",
    "    else:\n",
    "        im_patch = im[:, i:i+w, j:j+h]\n",
    "    return im_patch, i, j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch module\n",
    "\n",
    "This module contains the FCN based on the CNN module\n",
    "\n",
    "### Module structure\n",
    "\n",
    "For this module, we will try to implement the complex diagram describe in http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w4/Zhou_D-LinkNet_LinkNet_With_CVPR_2018_paper.pdf\n",
    "\n",
    "Usefull links:\n",
    "\n",
    "-Torch documentations (especially for the input/ouput size of Conv2d and ConvTranspose2d: https://pytorch.org/docs/stable/nn.html\n",
    "\n",
    "-This link to better understand what each argument in Conv2d and ConvTranspose2d: https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class takes our input of size 400*400 and enlarges it to size 512*512\n",
    "\n",
    "class FCN_DLinkNet(torch.nn.Module):\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(FCN_DLinkNet, self).__init__()\n",
    "        \n",
    "        # Encoding part\n",
    "        \n",
    "        self.convstart = torch.nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=58)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.convEncodBlock1 = torch.nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock2start = torch.nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock2 = torch.nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock3start = torch.nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock3 = torch.nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock4start = torch.nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock4 = torch.nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Center part\n",
    "        \n",
    "        self.convCenterdil1 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1) #same as convEncodBlock4 but added for clarity\n",
    "        self.convCenterdil2 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=2, dilation=2)\n",
    "        self.convCenterdil4 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=4, dilation=4)\n",
    "        self.convCenterdil8 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=8, dilation=8)\n",
    "        \n",
    "        # Decoding part\n",
    "        \n",
    "        self.convDecodBlock4start = torch.nn.Conv2d(512, 128, kernel_size=1)\n",
    "        self.deconvDecodBlock4 = torch.nn.ConvTranspose2d(128, 128, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock4end = torch.nn.Conv2d(128, 256, kernel_size=1)\n",
    "        \n",
    "        self.convDecodBlock3start = torch.nn.Conv2d(256, 64, kernel_size=1)\n",
    "        self.deconvDecodBlock3 = torch.nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock3end = torch.nn.Conv2d(64, 128, kernel_size=1)\n",
    "        \n",
    "        self.convDecodBlock2start = torch.nn.Conv2d(128, 32, kernel_size=1)\n",
    "        self.deconvDecodBlock2 = torch.nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock2end = torch.nn.Conv2d(32, 64, kernel_size=1)\n",
    "        \n",
    "        self.convDecodBlock1start = torch.nn.Conv2d(64, 16, kernel_size=1)\n",
    "        self.deconvDecodBlock1 = torch.nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock1end = torch.nn.Conv2d(16, 64, kernel_size=1)\n",
    "        \n",
    "        self.deconvDecodend = torch.nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=57)\n",
    "        self.convDecoddil1end = torch.nn.Conv2d(32, 2, kernel_size=3, stride=1, padding=1, dilation=1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        def codeBlock1(self, x):\n",
    "            for i in range(0, 3):\n",
    "                x_inter = F.relu(self.convEncodBlock1(x))\n",
    "                x_inter = F.relu(self.convEncodBlock1(x_inter))\n",
    "                # Moyenne\n",
    "                x = (x + x_inter)/2\n",
    "            return x\n",
    "\n",
    "        def codeBlock2(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock2start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock2(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :64, :, :] = x\n",
    "            # Moyenne\n",
    "            x = (new_x + x_inter)/2\n",
    "            for i in range(0, 3):\n",
    "                x_inter = F.relu(self.convEncodBlock2(x))\n",
    "                x_inter = F.relu(self.convEncodBlock2(x_inter))\n",
    "                # Moyenne\n",
    "                x = (x + x_inter)/2\n",
    "            return x\n",
    "\n",
    "        def codeBlock3(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock3start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock3(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :128, :, :] = x\n",
    "            # Moyenne\n",
    "            x = (new_x + x_inter)/2\n",
    "            for i in range(0, 5):\n",
    "                x_inter = F.relu(self.convEncodBlock3(x))\n",
    "                x_inter = F.relu(self.convEncodBlock3(x_inter))\n",
    "                # Moyenne\n",
    "                x = (x + x_inter)/2\n",
    "            return x\n",
    "\n",
    "        def codeBlock4(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock4start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock4(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :256, :, :] = x\n",
    "            # Moyenne\n",
    "            x = (new_x + x_inter)/2\n",
    "            for i in range(0, 2):\n",
    "                x_inter = F.relu(self.convEncodBlock4(x))\n",
    "                x_inter = F.relu(self.convEncodBlock4(x_inter))\n",
    "                # Moyenne\n",
    "                x = (x + x_inter)/2\n",
    "            return x\n",
    "\n",
    "        def decodeBlock4(self, x):\n",
    "            x = F.relu(self.convDecodBlock4start(x))\n",
    "            x = self.deconvDecodBlock4(x)\n",
    "            x = F.relu(self.convDecodBlock4end(x))\n",
    "            return x\n",
    "\n",
    "        def decodeBlock3(self, x):\n",
    "            x = F.relu(self.convDecodBlock3start(x))\n",
    "            x = self.deconvDecodBlock3(x)\n",
    "            x = F.relu(self.convDecodBlock3end(x))\n",
    "            return x\n",
    "\n",
    "        def decodeBlock2(self, x):\n",
    "            x = F.relu(self.convDecodBlock2start(x))\n",
    "            x = self.deconvDecodBlock2(x)\n",
    "            x = F.relu(self.convDecodBlock2end(x))\n",
    "            return x\n",
    "\n",
    "        def decodeBlock1(self, x):\n",
    "            x = F.relu(self.convDecodBlock1start(x))\n",
    "            x = self.deconvDecodBlock1(x)\n",
    "            x = F.relu(self.convDecodBlock1end(x))\n",
    "            return x\n",
    "        \n",
    "        x_start = F.relu(self.convstart(x))\n",
    "        x_start = self.pool(x_start)\n",
    "        \n",
    "        x_codeBlock1 = codeBlock1(self, x_start)\n",
    "        x_codeBlock2 = codeBlock2(self, x_codeBlock1)\n",
    "        x_codeBlock3 = codeBlock3(self, x_codeBlock2)\n",
    "        x_codeBlock4 = codeBlock4(self, x_codeBlock3)\n",
    "        \n",
    "        x_center1 = F.relu(self.convCenterdil1(x_codeBlock4))\n",
    "        x_center2 = F.relu(self.convCenterdil2(x_center1))\n",
    "        x_center3 = F.relu(self.convCenterdil4(x_center2))\n",
    "        x_center4 = F.relu(self.convCenterdil8(x_center3))\n",
    "        \n",
    "        x_center_final = (x_codeBlock4 + x_center1 + x_center2 + x_center3 + x_center4)/5\n",
    "        \n",
    "        x_decodeBlock4 = decodeBlock4(self, x_center_final)\n",
    "        x_decodeBlock3 = decodeBlock3(self, (x_decodeBlock4 + x_codeBlock3)/2)\n",
    "        x_decodeBlock2 = decodeBlock2(self, (x_decodeBlock3 + x_codeBlock2)/2)\n",
    "        x_decodeBlock1 = decodeBlock1(self, (x_decodeBlock2 + x_codeBlock1)/2)\n",
    "        \n",
    "        x_end = self.deconvDecodend(x_decodeBlock1)\n",
    "        x_end = F.relu(self.convDecoddil1end(x_end))\n",
    "        x_end = self.sigmoid(x_end)\n",
    "        \n",
    "        return(x_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class takes our input of size 400*400 and directly put it to size 256*256\n",
    "\n",
    "class FCN_DLinkNet_new(torch.nn.Module):\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(FCN_DLinkNet_new, self).__init__()\n",
    "        \n",
    "        # Encoding part\n",
    "        \n",
    "        self.convstart = torch.nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=57)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        \n",
    "        self.convEncodBlock1 = torch.nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock2start = torch.nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock2 = torch.nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock3start = torch.nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock3 = torch.nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock4start = torch.nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock4 = torch.nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Center part\n",
    "        \n",
    "        self.convCenterdil1 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1) #same as convEncodBlock4 but added for clarity\n",
    "        self.convCenterdil2 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=2, dilation=2)\n",
    "        self.convCenterdil4 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=4, dilation=4)\n",
    "        self.convCenterdil8 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=8, dilation=8)\n",
    "        \n",
    "        # Decoding part\n",
    "        \n",
    "        self.convDecodBlock4start = torch.nn.Conv2d(512, 128, kernel_size=1)\n",
    "        self.deconvDecodBlock4 = torch.nn.ConvTranspose2d(128, 128, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock4end = torch.nn.Conv2d(128, 256, kernel_size=1)\n",
    "        self.normback4 = torch.nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.convDecodBlock3start = torch.nn.Conv2d(256, 64, kernel_size=1)\n",
    "        self.deconvDecodBlock3 = torch.nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock3end = torch.nn.Conv2d(64, 128, kernel_size=1)\n",
    "        self.normback3 = torch.nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.convDecodBlock2start = torch.nn.Conv2d(128, 32, kernel_size=1)\n",
    "        self.deconvDecodBlock2 = torch.nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock2end = torch.nn.Conv2d(32, 64, kernel_size=1)\n",
    "        self.normback2 = torch.nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.convDecodBlock1start = torch.nn.Conv2d(64, 16, kernel_size=1)\n",
    "        self.deconvDecodBlock1 = torch.nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock1end = torch.nn.Conv2d(16, 64, kernel_size=1)\n",
    "        self.normback1 = torch.nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.deconvDecodend = torch.nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=57)\n",
    "        self.convDecoddil1end = torch.nn.Conv2d(32, 2, kernel_size=3, stride=1, padding=1, dilation=1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        def codeBlock1(self, x):\n",
    "            for i in range(0, 3):\n",
    "                x_inter = F.relu(self.convEncodBlock1(x))\n",
    "                x_inter = F.relu(self.convEncodBlock1(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def codeBlock2(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock2start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock2(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :64, :, :] = x\n",
    "            # Moyenne\n",
    "            x = new_x + x_inter\n",
    "            for i in range(0, 3):\n",
    "                x_inter = F.relu(self.convEncodBlock2(x))\n",
    "                x_inter = F.relu(self.convEncodBlock2(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def codeBlock3(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock3start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock3(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :128, :, :] = x\n",
    "            # Moyenne\n",
    "            x = new_x + x_inter\n",
    "            for i in range(0, 5):\n",
    "                x_inter = F.relu(self.convEncodBlock3(x))\n",
    "                x_inter = F.relu(self.convEncodBlock3(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def codeBlock4(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock4start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock4(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :256, :, :] = x\n",
    "            # Moyenne\n",
    "            x = new_x + x_inter\n",
    "            for i in range(0, 2):\n",
    "                x_inter = F.relu(self.convEncodBlock4(x))\n",
    "                x_inter = F.relu(self.convEncodBlock4(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def decodeBlock4(self, x):\n",
    "            x = F.relu(self.convDecodBlock4start(x))\n",
    "            x = self.deconvDecodBlock4(x)\n",
    "            x = F.relu(self.convDecodBlock4end(x))\n",
    "            x = self.normback4(x)\n",
    "            return x\n",
    "\n",
    "        def decodeBlock3(self, x):\n",
    "            x = F.relu(self.convDecodBlock3start(x))\n",
    "            x = self.deconvDecodBlock3(x)\n",
    "            x = F.relu(self.convDecodBlock3end(x))\n",
    "            x = self.normback3(x)\n",
    "            return x\n",
    "\n",
    "        def decodeBlock2(self, x):\n",
    "            x = F.relu(self.convDecodBlock2start(x))\n",
    "            x = self.deconvDecodBlock2(x)\n",
    "            x = F.relu(self.convDecodBlock2end(x))\n",
    "            x = self.normback2(x)\n",
    "            return x\n",
    "\n",
    "        def decodeBlock1(self, x):\n",
    "            x = F.relu(self.convDecodBlock1start(x))\n",
    "            x = self.deconvDecodBlock1(x)\n",
    "            x = F.relu(self.convDecodBlock1end(x))\n",
    "            x = self.normback1(x)\n",
    "            return x\n",
    "        \n",
    "        x_start = F.relu(self.convstart(x))\n",
    "        \n",
    "        x_codeBlock1 = codeBlock1(self, x_start)\n",
    "        x_codeBlock2 = codeBlock2(self, x_codeBlock1)\n",
    "        x_codeBlock3 = codeBlock3(self, x_codeBlock2)\n",
    "        x_codeBlock4 = codeBlock4(self, x_codeBlock3)\n",
    "        \n",
    "        x_center1 = F.relu(self.convCenterdil1(x_codeBlock4))\n",
    "        x_center2 = F.relu(self.convCenterdil2(x_center1))\n",
    "        x_center3 = F.relu(self.convCenterdil4(x_center2))\n",
    "        x_center4 = F.relu(self.convCenterdil8(x_center3))\n",
    "        \n",
    "        x_center_final = x_codeBlock4 + x_center1 + x_center2 + x_center3 + x_center4\n",
    "        \n",
    "        x_decodeBlock4 = decodeBlock4(self, x_center_final)\n",
    "        x_decodeBlock3 = decodeBlock3(self, x_decodeBlock4 + x_codeBlock3)\n",
    "        x_decodeBlock2 = decodeBlock2(self, x_decodeBlock3 + x_codeBlock2)\n",
    "        x_decodeBlock1 = decodeBlock1(self, x_decodeBlock2 + x_codeBlock1)\n",
    "        \n",
    "        x_end = self.deconvDecodend(x_decodeBlock1)\n",
    "        x_end = F.relu(self.convDecoddil1end(x_end))\n",
    "        x_end = self.sigmoid(x_end)\n",
    "        \n",
    "        return(x_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class takes our input of size 400*400 and directly put it to size 256*256\n",
    "\n",
    "class FCN_DLinkNet_direct(torch.nn.Module):\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(FCN_DLinkNet_direct, self).__init__()\n",
    "        \n",
    "        # Encoding part\n",
    "        \n",
    "        self.convstart = torch.nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.convEncodBlock1 = torch.nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock2start = torch.nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock2 = torch.nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock3start = torch.nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock3 = torch.nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock4start = torch.nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock4 = torch.nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Center part\n",
    "        \n",
    "        self.convCenterdil1 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1) #same as convEncodBlock4 but added for clarity\n",
    "        self.convCenterdil2 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=2, dilation=2)\n",
    "        self.convCenterdil4 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=4, dilation=4)\n",
    "        self.convCenterdil8 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=8, dilation=8)\n",
    "        \n",
    "        # Decoding part\n",
    "        \n",
    "        self.convDecodBlock4start = torch.nn.Conv2d(512, 128, kernel_size=1)\n",
    "        self.deconvDecodBlock4 = torch.nn.ConvTranspose2d(128, 128, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock4end = torch.nn.Conv2d(128, 256, kernel_size=1)\n",
    "        \n",
    "        self.convDecodBlock3start = torch.nn.Conv2d(256, 64, kernel_size=1)\n",
    "        self.deconvDecodBlock3 = torch.nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock3end = torch.nn.Conv2d(64, 128, kernel_size=1)\n",
    "        \n",
    "        self.convDecodBlock2start = torch.nn.Conv2d(128, 32, kernel_size=1)\n",
    "        self.deconvDecodBlock2 = torch.nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock2end = torch.nn.Conv2d(32, 64, kernel_size=1)\n",
    "        \n",
    "        self.convDecodBlock1start = torch.nn.Conv2d(64, 16, kernel_size=1)\n",
    "        self.deconvDecodBlock1 = torch.nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock1end = torch.nn.Conv2d(16, 64, kernel_size=1)\n",
    "        \n",
    "        self.deconvDecodend = torch.nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.convDecoddil1end = torch.nn.Conv2d(32, 2, kernel_size=3, stride=2, padding=2, dilation=2)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        def codeBlock1(self, x):\n",
    "            for i in range(0, 3):\n",
    "                x_inter = F.relu(self.convEncodBlock1(x))\n",
    "                x_inter = F.relu(self.convEncodBlock1(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def codeBlock2(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock2start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock2(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :64, :, :] = x\n",
    "            # Moyenne\n",
    "            x = new_x + x_inter\n",
    "            for i in range(0, 3):\n",
    "                x_inter = F.relu(self.convEncodBlock2(x))\n",
    "                x_inter = F.relu(self.convEncodBlock2(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def codeBlock3(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock3start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock3(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :128, :, :] = x\n",
    "            # Moyenne\n",
    "            x = new_x + x_inter\n",
    "            for i in range(0, 5):\n",
    "                x_inter = F.relu(self.convEncodBlock3(x))\n",
    "                x_inter = F.relu(self.convEncodBlock3(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def codeBlock4(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock4start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock4(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :256, :, :] = x\n",
    "            # Moyenne\n",
    "            x = new_x + x_inter\n",
    "            for i in range(0, 2):\n",
    "                x_inter = F.relu(self.convEncodBlock4(x))\n",
    "                x_inter = F.relu(self.convEncodBlock4(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def decodeBlock4(self, x):\n",
    "            x = F.relu(self.convDecodBlock4start(x))\n",
    "            x = self.deconvDecodBlock4(x)\n",
    "            x = F.relu(self.convDecodBlock4end(x))\n",
    "            return x\n",
    "\n",
    "        def decodeBlock3(self, x):\n",
    "            x = F.relu(self.convDecodBlock3start(x))\n",
    "            x = self.deconvDecodBlock3(x)\n",
    "            x = F.relu(self.convDecodBlock3end(x))\n",
    "            return x\n",
    "\n",
    "        def decodeBlock2(self, x):\n",
    "            x = F.relu(self.convDecodBlock2start(x))\n",
    "            x = self.deconvDecodBlock2(x)\n",
    "            x = F.relu(self.convDecodBlock2end(x))\n",
    "            return x\n",
    "\n",
    "        def decodeBlock1(self, x):\n",
    "            x = F.relu(self.convDecodBlock1start(x))\n",
    "            x = self.deconvDecodBlock1(x)\n",
    "            x = F.relu(self.convDecodBlock1end(x))\n",
    "            return x\n",
    "        \n",
    "        x_start = F.relu(self.convstart(x))\n",
    "        \n",
    "        x_codeBlock1 = codeBlock1(self, x_start)\n",
    "        x_codeBlock2 = codeBlock2(self, x_codeBlock1)\n",
    "        x_codeBlock3 = codeBlock3(self, x_codeBlock2)\n",
    "        x_codeBlock4 = codeBlock4(self, x_codeBlock3)\n",
    "        \n",
    "        x_center1 = F.relu(self.convCenterdil1(x_codeBlock4))\n",
    "        x_center2 = F.relu(self.convCenterdil2(x_center1))\n",
    "        x_center3 = F.relu(self.convCenterdil4(x_center2))\n",
    "        x_center4 = F.relu(self.convCenterdil8(x_center3))\n",
    "        \n",
    "        x_center_final = x_codeBlock4 + x_center1 + x_center2 + x_center3 + x_center4\n",
    "        \n",
    "        x_decodeBlock4 = decodeBlock4(self, x_center_final)\n",
    "        x_decodeBlock3 = decodeBlock3(self, x_decodeBlock4 + x_codeBlock3)\n",
    "        x_decodeBlock2 = decodeBlock2(self, x_decodeBlock3 + x_codeBlock2)\n",
    "        x_decodeBlock1 = decodeBlock1(self, x_decodeBlock2 + x_codeBlock1)\n",
    "        \n",
    "        x_end = self.deconvDecodend(x_decodeBlock1)\n",
    "        x_end = F.relu(self.convDecoddil1end(x_end))\n",
    "        x_end = self.sigmoid(x_end)\n",
    "        \n",
    "        return(x_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model optimized with adam and cross entropy will converge to all-black images every time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 images\n",
      "(100, 3, 400, 400)\n",
      "Loading 100 images\n",
      "(100, 400, 400)\n"
     ]
    }
   ],
   "source": [
    "end_train = 15 # normally = 90\n",
    "end_validation = 20 # normally = 100\n",
    "\n",
    "# Loading a set of 100 training images\n",
    "root_dir = \"training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = min(100, len(files)) # Load maximum 100 images\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = np.array([load_image(image_dir + files[i]) for i in range(n)]).swapaxes(1,3).swapaxes(2,3)\n",
    "print(np.shape(imgs))\n",
    "\n",
    "train_input = imgs[0:end_train] #normally = 0:90\n",
    "validation_input = imgs[end_train:end_validation] #normally = 90:100\n",
    "\n",
    "image_dir = root_dir + \"groundtruth/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = min(100, len(files)) # Load maximum 100 images\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "grounds = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "print(np.shape(grounds))\n",
    "\n",
    "train_target = grounds[0:end_train] #normally = 0:90\n",
    "validation_target = grounds[end_train:end_validation] #normally = 90:100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 3, 256, 256)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5, 3, 256, 256)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 256, 256)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5, 256, 256)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# crop images to their 256*256 counterparts\n",
    "cropped_imgs = []\n",
    "cropped_targets = []\n",
    "\n",
    "for i in range(end_validation):\n",
    "    cropped_img, k, l = img_rnd_crop(imgs[i], 256, 256)\n",
    "    cropped_target, _, _ = img_rnd_crop(grounds[i], 256, 256, k, l)\n",
    "    cropped_imgs.append(cropped_img)\n",
    "    cropped_targets.append(cropped_target)\n",
    "    \n",
    "train_input = cropped_imgs[0:end_train] #normally = 0:90\n",
    "validation_input = cropped_imgs[end_train:end_validation] #normally = 90:100\n",
    "\n",
    "\n",
    "train_target = cropped_targets[0:end_train] #normally = 0:90\n",
    "validation_target = cropped_targets[end_train:end_validation] #normally = 90:100\n",
    "\n",
    "display(np.shape(train_input))\n",
    "display(np.shape(validation_input))\n",
    "display(np.shape(train_target))\n",
    "display(np.shape(validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep 10 images from this set as a validation set.\n",
    "To shorten the computationnal time we will use a smaller amount of images to do tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the model, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We will optimize the cross-entropy loss using adam algorithm\n",
    "net = FCN_DLinkNet_direct()\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "optimizer = optim.SGD(net.parameters(), lr=3.75e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNet(net, n_epochs):\n",
    "    \n",
    "    #Time for printing\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    #Loop for n_epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for index in range(np.shape(train_input)[0]):\n",
    "            \n",
    "            input_image = Variable(torch.tensor(train_input[index], requires_grad=True).unsqueeze(0))\n",
    "            target_image = Variable(torch.tensor(train_target[index], dtype=torch.long).unsqueeze(0))\n",
    "            \n",
    "            #Set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Forward pass, backward pass, optimize\n",
    "            outputs = net(input_image)\n",
    "            loss = loss_function(outputs, target_image)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Print statistics\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            print(\"Epoch\", epoch, \", image\", index, \", image loss:\", loss.item(), \", time elapsed:\", time.time() - training_start_time)\n",
    "            \n",
    "        #At the end of the epoch, do a pass on the validation set\n",
    "        total_val_loss = 0\n",
    "        for index in range(np.shape(validation_input)[0]):\n",
    "            \n",
    "            input_image = Variable(torch.tensor(validation_input[index], requires_grad=True).unsqueeze(0))\n",
    "            target_image = Variable(torch.tensor(validation_target[index], dtype=torch.long).unsqueeze(0))\n",
    "            \n",
    "            #Forward pass\n",
    "            val_outputs = net(input_image)\n",
    "            val_loss = loss_function(val_outputs, target_image)\n",
    "            total_val_loss += val_loss.item()\n",
    "            \n",
    "        print(\"Validation loss for epoch\", epoch, \":\", total_val_loss/np.shape(validation_input)[0])\n",
    "        \n",
    "    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 , image 0 , image loss: 0.6928009390830994 , time elapsed: 12.469127178192139\n",
      "Epoch 0 , image 1 , image loss: 0.6928002834320068 , time elapsed: 25.279097080230713\n",
      "Epoch 0 , image 2 , image loss: 0.6928006410598755 , time elapsed: 38.3987033367157\n",
      "Epoch 0 , image 3 , image loss: 0.6927999258041382 , time elapsed: 51.5139946937561\n",
      "Epoch 0 , image 4 , image loss: 0.6927993297576904 , time elapsed: 64.57326579093933\n",
      "Epoch 0 , image 5 , image loss: 0.6927984952926636 , time elapsed: 77.8407232761383\n",
      "Epoch 0 , image 6 , image loss: 0.6927977204322815 , time elapsed: 91.26910710334778\n",
      "Epoch 0 , image 7 , image loss: 0.6927964687347412 , time elapsed: 105.29914331436157\n",
      "Epoch 0 , image 8 , image loss: 0.6927935481071472 , time elapsed: 118.72993350028992\n",
      "Epoch 0 , image 9 , image loss: 0.6927924752235413 , time elapsed: 131.98312783241272\n",
      "Epoch 0 , image 10 , image loss: 0.6927905082702637 , time elapsed: 145.96418142318726\n",
      "Epoch 0 , image 11 , image loss: 0.6927890777587891 , time elapsed: 160.18575429916382\n",
      "Epoch 0 , image 12 , image loss: 0.692786455154419 , time elapsed: 173.7231307029724\n",
      "Epoch 0 , image 13 , image loss: 0.6927839517593384 , time elapsed: 188.04668593406677\n",
      "Epoch 0 , image 14 , image loss: 0.6927822828292847 , time elapsed: 203.023695230484\n",
      "Validation loss for epoch 0 : 0.6927738666534424\n",
      "Epoch 1 , image 0 , image loss: 0.6927745342254639 , time elapsed: 248.18470072746277\n",
      "Epoch 1 , image 1 , image loss: 0.692523181438446 , time elapsed: 261.5636842250824\n",
      "Epoch 1 , image 2 , image loss: 0.6878385543823242 , time elapsed: 274.68371772766113\n",
      "Epoch 1 , image 3 , image loss: 0.6798496842384338 , time elapsed: 287.91264295578003\n",
      "Epoch 1 , image 4 , image loss: 0.6683791875839233 , time elapsed: 301.2864809036255\n",
      "Epoch 1 , image 5 , image loss: 0.6544283032417297 , time elapsed: 314.870534658432\n",
      "Epoch 1 , image 6 , image loss: 0.6371476650238037 , time elapsed: 328.1506915092468\n",
      "Epoch 1 , image 7 , image loss: 0.6174956560134888 , time elapsed: 341.90548300743103\n",
      "Epoch 1 , image 8 , image loss: 0.5944005250930786 , time elapsed: 355.2976849079132\n",
      "Epoch 1 , image 9 , image loss: 0.5699028968811035 , time elapsed: 368.5488669872284\n",
      "Epoch 1 , image 10 , image loss: 0.544651985168457 , time elapsed: 382.2038559913635\n",
      "Epoch 1 , image 11 , image loss: 0.5219864249229431 , time elapsed: 395.29764771461487\n",
      "Epoch 1 , image 12 , image loss: 0.5037894248962402 , time elapsed: 408.5696692466736\n",
      "Epoch 1 , image 13 , image loss: 0.49078115820884705 , time elapsed: 421.57368302345276\n",
      "Epoch 1 , image 14 , image loss: 0.48291829228401184 , time elapsed: 434.79665899276733\n",
      "Validation loss for epoch 1 : 0.47879955768585203\n",
      "Epoch 2 , image 0 , image loss: 0.4788002073764801 , time elapsed: 478.9476969242096\n",
      "Epoch 2 , image 1 , image loss: 0.4766749143600464 , time elapsed: 492.0886676311493\n",
      "Epoch 2 , image 2 , image loss: 0.47514498233795166 , time elapsed: 504.82373452186584\n",
      "Epoch 2 , image 3 , image loss: 0.47470352053642273 , time elapsed: 518.4236478805542\n",
      "Epoch 2 , image 4 , image loss: 0.4746405780315399 , time elapsed: 532.2012596130371\n",
      "Epoch 2 , image 5 , image loss: 0.4745340347290039 , time elapsed: 548.2404336929321\n",
      "Epoch 2 , image 6 , image loss: 0.4745114743709564 , time elapsed: 567.2860977649689\n",
      "Epoch 2 , image 7 , image loss: 0.4744966924190521 , time elapsed: 585.3010580539703\n",
      "Epoch 2 , image 8 , image loss: 0.474237859249115 , time elapsed: 603.2953388690948\n",
      "Epoch 2 , image 9 , image loss: 0.47423243522644043 , time elapsed: 617.5153150558472\n",
      "Epoch 2 , image 10 , image loss: 0.47422894835472107 , time elapsed: 630.4507265090942\n",
      "Epoch 2 , image 11 , image loss: 0.47422686219215393 , time elapsed: 642.3120105266571\n",
      "Epoch 2 , image 12 , image loss: 0.47422605752944946 , time elapsed: 655.3340072631836\n",
      "Epoch 2 , image 13 , image loss: 0.47422555088996887 , time elapsed: 670.0918524265289\n",
      "Epoch 2 , image 14 , image loss: 0.474225252866745 , time elapsed: 684.7092382907867\n",
      "Validation loss for epoch 2 : 0.47422492504119873\n",
      "Training finished, took 719.98s\n"
     ]
    }
   ],
   "source": [
    "trainNet(net, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.tensor(validation_input[0]).unsqueeze(0)\n",
    "target_image = torch.tensor(validation_target[0]).unsqueeze(0)\n",
    "           \n",
    "#Forward pass\n",
    "val_output = net(input_image)\n",
    "output_image = val_output[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17d9720a5c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(target_image.squeeze(0), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17da310c0f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(output_image.detach().numpy(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
