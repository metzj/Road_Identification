{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "This notebook contains a test CNN in pytorch, to get familiar with this developping environment. It also acts as a template for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x194d5101070>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os,sys\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "#seed for reproducible results\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - np.min(img)\n",
    "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "    return rimg\n",
    "\n",
    "# Concatenate an image and its groundtruth\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = np.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch module\n",
    "\n",
    "This module contains the CNN named SimpleCNN.\n",
    "\n",
    "In \"init\", the layers have to be initialized (for instance conv layers, maxpool layers and fully connected layers. ReLu do not take hyperparameters, so it doesn't need an initialization.\n",
    "\n",
    "In \"forward\", the structure of the CNN is laid out by taking an input tensor x and applying the layers in the correct order to this tensor. This function is the forward pass of the CNN and returns the computed x.\n",
    "\n",
    "The backward pass can be computed by Pytorch's autograd function. For this to be achieved, our input tensor and our weights must be of type \"Variable\" (as imported above), this type stores changes to the tensor automatically which makes it possible to compute the gradient very easily. When declaring a Variable tensor, the option \"requires_grad\" must be set to True, otherwise the gradient will not be computed.\n",
    "\n",
    "### Module structure\n",
    "\n",
    "For this example module, we will define a fully convolutional neural network (FCN), with three convolutional layers and one transposed convolution (or deconvolution) to upsample the results of the convolutions.\n",
    "\n",
    "\n",
    "- Input image: 3 channels 400x400\n",
    "\n",
    "Three convolutions layers so that spatial stuff happen (every parameter is pretty arbitrary right now)\n",
    "- Convolution with kernel size 5, reduce to 1 channel (output  1 channel 396x396)\n",
    "- ReLu\n",
    "- MaxPool with kernel size 2 (output 198x198)\n",
    "- Convolution with kernel size 17 (output 182x182)\n",
    "- ReLu\n",
    "- MaxPool with kernel size 2 (output 91x91)\n",
    "- Convolution with kernel size 22 (output 70x70)\n",
    "- ReLu\n",
    "- MaxPool with kernel size 2 (output 35x35)\n",
    "\n",
    "A transposed convolution layer\n",
    "- Deconv with kernel size 400-35+1=366 (output 400x400)\n",
    "- Sigmoid for the binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_3conv_1deconv(torch.nn.Module):\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(FCN_3conv_1deconv, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(3, 1, kernel_size=5)\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(1, 1, kernel_size=17)\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv3 = torch.nn.Conv2d(1, 1, kernel_size=22)\n",
    "        self.pool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.deconv = torch.nn.ConvTranspose2d(1, 2, kernel_size=366)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.deconv(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model optimized with adam and cross entropy will converge to all-black images every time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 images\n",
      "(100, 3, 400, 400)\n",
      "Loading 100 images\n",
      "(100, 400, 400)\n"
     ]
    }
   ],
   "source": [
    "# Loading a set of 100 training images\n",
    "root_dir = \"training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = min(100, len(files)) # Load maximum 100 images\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = np.array([load_image(image_dir + files[i]) for i in range(n)]).swapaxes(1,3).swapaxes(2,3)\n",
    "print(np.shape(imgs))\n",
    "\n",
    "train_input = imgs[0:90]\n",
    "validation_input = imgs[90:100]\n",
    "\n",
    "image_dir = root_dir + \"groundtruth/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = min(100, len(files)) # Load maximum 100 images\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "print(np.shape(imgs))\n",
    "\n",
    "train_target = imgs[0:90]\n",
    "validation_target = imgs[90:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep 10 images from this set as a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the model, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We will optimize the cross-entropy loss using adam algorithm\n",
    "net = FCN_3conv_1deconv()\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNet(net, n_epochs):\n",
    "    \n",
    "    #Time for printing\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    #Loop for n_epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for index in range(np.shape(train_input)[0]):\n",
    "            \n",
    "            input_image = Variable(torch.tensor(train_input[index], requires_grad=True).unsqueeze(0))\n",
    "            target_image = Variable(torch.tensor(train_target[index], dtype=torch.long).unsqueeze(0))\n",
    "            \n",
    "            #Set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Forward pass, backward pass, optimize\n",
    "            outputs = net(input_image)\n",
    "            loss = loss_function(outputs, target_image)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Print statistics\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            print(\"Epoch\", epoch, \", image\", index, \", image loss:\", loss.item(), \", time elapsed:\", time.time() - training_start_time)\n",
    "            \n",
    "        #At the end of the epoch, do a pass on the validation set\n",
    "        total_val_loss = 0\n",
    "        for index in range(np.shape(validation_input)[0]):\n",
    "            \n",
    "            input_image = Variable(torch.tensor(validation_input[index], requires_grad=True).unsqueeze(0))\n",
    "            target_image = Variable(torch.tensor(validation_target[index], dtype=torch.long).unsqueeze(0))\n",
    "            \n",
    "            #Forward pass\n",
    "            val_outputs = net(input_image)\n",
    "            val_loss = loss_function(val_outputs, target_image)\n",
    "            total_val_loss += val_loss.item()\n",
    "            \n",
    "        print(\"Validation loss for epoch\", epoch, \":\", total_val_loss/np.shape(validation_input)[0])\n",
    "        \n",
    "    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 , image 0 , image loss: 0.693555474281311 , time elapsed: 3.1247904300689697\n",
      "Epoch 0 , image 1 , image loss: 0.6882050037384033 , time elapsed: 6.273568153381348\n",
      "Epoch 0 , image 2 , image loss: 0.6805382370948792 , time elapsed: 8.800349235534668\n",
      "Epoch 0 , image 3 , image loss: 0.6692225337028503 , time elapsed: 11.505416631698608\n",
      "Epoch 0 , image 4 , image loss: 0.6473919153213501 , time elapsed: 14.258381605148315\n",
      "Epoch 0 , image 5 , image loss: 0.610875129699707 , time elapsed: 16.722432851791382\n",
      "Epoch 0 , image 6 , image loss: 0.5732976794242859 , time elapsed: 19.156139373779297\n",
      "Epoch 0 , image 7 , image loss: 0.5185819268226624 , time elapsed: 21.636812210083008\n",
      "Epoch 0 , image 8 , image loss: 0.45166683197021484 , time elapsed: 24.150572299957275\n",
      "Epoch 0 , image 9 , image loss: 0.39871588349342346 , time elapsed: 26.619473695755005\n",
      "Epoch 0 , image 10 , image loss: 0.37921154499053955 , time elapsed: 29.102211236953735\n",
      "Epoch 0 , image 11 , image loss: 0.33413729071617126 , time elapsed: 31.679013967514038\n",
      "Epoch 0 , image 12 , image loss: 0.32467877864837646 , time elapsed: 34.19750738143921\n",
      "Epoch 0 , image 13 , image loss: 0.3197529911994934 , time elapsed: 36.63532519340515\n",
      "Epoch 0 , image 14 , image loss: 0.31850796937942505 , time elapsed: 39.11519718170166\n",
      "Epoch 0 , image 15 , image loss: 0.31607282161712646 , time elapsed: 41.568604707717896\n",
      "Epoch 0 , image 16 , image loss: 0.3156043291091919 , time elapsed: 44.018341064453125\n",
      "Epoch 0 , image 17 , image loss: 0.31440863013267517 , time elapsed: 46.465407371520996\n",
      "Epoch 0 , image 18 , image loss: 0.31398463249206543 , time elapsed: 49.595816135406494\n",
      "Epoch 0 , image 19 , image loss: 0.31359660625457764 , time elapsed: 54.31066846847534\n",
      "Epoch 0 , image 20 , image loss: 0.31410643458366394 , time elapsed: 56.779061794281006\n",
      "Epoch 0 , image 21 , image loss: 0.31356337666511536 , time elapsed: 60.71649360656738\n",
      "Epoch 0 , image 22 , image loss: 0.31317269802093506 , time elapsed: 63.360201597213745\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-06c24c4bb630>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-23a6029e16fc>\u001b[0m in \u001b[0;36mtrainNet\u001b[1;34m(net, n_epochs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;31m#Forward pass, backward pass, optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\ntds_2018\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-57a9106d6159>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\ntds_2018\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\ntds_2018\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, output_size)\u001b[0m\n\u001b[0;32m    755\u001b[0m         return F.conv_transpose2d(\n\u001b[0;32m    756\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainNet(net, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.tensor(validation_input[5]).unsqueeze(0)\n",
    "target_image = torch.tensor(validation_target[5]).unsqueeze(0)\n",
    "           \n",
    "#Forward pass\n",
    "val_output = net(input_image)\n",
    "output_image = val_output[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x194d9affeb8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(target_image.squeeze(0), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x194d9b986a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(output_image.detach().numpy(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
