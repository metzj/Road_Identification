{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCN\n",
    "This notebook contains a test CNN in pytorch, to get familiar with this developping environment. It also acts as a template for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os,sys\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "#seed for reproducible results\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - np.min(img)\n",
    "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "    return rimg\n",
    "\n",
    "# Concatenate an image and its groundtruth\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = np.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def uniform(a,b):\n",
    "    return(a+(b-a)*random())\n",
    "\n",
    "def img_rnd_crop(im, w, h, i = -1, j = -1):\n",
    "    is_2d = len(im.shape) < 3\n",
    "    imgwidth = im.shape[len(im.shape)-2]\n",
    "    imgheight = im.shape[len(im.shape)-1]\n",
    "    if (i == -1 and j == -1):\n",
    "        i = int(uniform(0, imgwidth-w-1))\n",
    "        j = int(uniform(0, imgheight-h-1))\n",
    "    if is_2d:\n",
    "        im_patch = im[i:i+w, j:j+h]\n",
    "    else:\n",
    "        im_patch = im[:, i:i+w, j:j+h]\n",
    "    return im_patch, i, j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch module\n",
    "\n",
    "This module contains the FCN based on the CNN module\n",
    "\n",
    "### Module structure\n",
    "\n",
    "For this module, we will try to implement the complex diagram describe in http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w4/Zhou_D-LinkNet_LinkNet_With_CVPR_2018_paper.pdf\n",
    "\n",
    "Usefull links:\n",
    "\n",
    "-Torch documentations (especially for the input/ouput size of Conv2d and ConvTranspose2d: https://pytorch.org/docs/stable/nn.html\n",
    "\n",
    "-This link to better understand what each argument in Conv2d and ConvTranspose2d: https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class takes our input of size 400*400 and enlarges it to size 512*512\n",
    "\n",
    "class FCN_DLinkNet(torch.nn.Module):\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(FCN_DLinkNet, self).__init__()\n",
    "        \n",
    "        # Encoding part\n",
    "        \n",
    "        self.convstart = torch.nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=58)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.convEncodBlock1 = torch.nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock2start = torch.nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock2 = torch.nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock3start = torch.nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock3 = torch.nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock4start = torch.nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock4 = torch.nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Center part\n",
    "        \n",
    "        self.convCenterdil1 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1) #same as convEncodBlock4 but added for clarity\n",
    "        self.convCenterdil2 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=2, dilation=2)\n",
    "        self.convCenterdil4 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=4, dilation=4)\n",
    "        self.convCenterdil8 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=8, dilation=8)\n",
    "        \n",
    "        # Decoding part\n",
    "        \n",
    "        self.convDecodBlock4start = torch.nn.Conv2d(512, 128, kernel_size=1)\n",
    "        self.deconvDecodBlock4 = torch.nn.ConvTranspose2d(128, 128, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock4end = torch.nn.Conv2d(128, 256, kernel_size=1)\n",
    "        \n",
    "        self.convDecodBlock3start = torch.nn.Conv2d(256, 64, kernel_size=1)\n",
    "        self.deconvDecodBlock3 = torch.nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock3end = torch.nn.Conv2d(64, 128, kernel_size=1)\n",
    "        \n",
    "        self.convDecodBlock2start = torch.nn.Conv2d(128, 32, kernel_size=1)\n",
    "        self.deconvDecodBlock2 = torch.nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock2end = torch.nn.Conv2d(32, 64, kernel_size=1)\n",
    "        \n",
    "        self.convDecodBlock1start = torch.nn.Conv2d(64, 16, kernel_size=1)\n",
    "        self.deconvDecodBlock1 = torch.nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock1end = torch.nn.Conv2d(16, 64, kernel_size=1)\n",
    "        \n",
    "        self.deconvDecodend = torch.nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=57)\n",
    "        self.convDecoddil1end = torch.nn.Conv2d(32, 2, kernel_size=3, stride=1, padding=1, dilation=1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        def codeBlock1(self, x):\n",
    "            for i in range(0, 3):\n",
    "                x_inter = F.relu(self.convEncodBlock1(x))\n",
    "                x_inter = F.relu(self.convEncodBlock1(x_inter))\n",
    "                # Moyenne\n",
    "                x = (x + x_inter)/2\n",
    "            return x\n",
    "\n",
    "        def codeBlock2(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock2start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock2(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :64, :, :] = x\n",
    "            # Moyenne\n",
    "            x = (new_x + x_inter)/2\n",
    "            for i in range(0, 3):\n",
    "                x_inter = F.relu(self.convEncodBlock2(x))\n",
    "                x_inter = F.relu(self.convEncodBlock2(x_inter))\n",
    "                # Moyenne\n",
    "                x = (x + x_inter)/2\n",
    "            return x\n",
    "\n",
    "        def codeBlock3(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock3start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock3(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :128, :, :] = x\n",
    "            # Moyenne\n",
    "            x = (new_x + x_inter)/2\n",
    "            for i in range(0, 5):\n",
    "                x_inter = F.relu(self.convEncodBlock3(x))\n",
    "                x_inter = F.relu(self.convEncodBlock3(x_inter))\n",
    "                # Moyenne\n",
    "                x = (x + x_inter)/2\n",
    "            return x\n",
    "\n",
    "        def codeBlock4(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock4start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock4(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :256, :, :] = x\n",
    "            # Moyenne\n",
    "            x = (new_x + x_inter)/2\n",
    "            for i in range(0, 2):\n",
    "                x_inter = F.relu(self.convEncodBlock4(x))\n",
    "                x_inter = F.relu(self.convEncodBlock4(x_inter))\n",
    "                # Moyenne\n",
    "                x = (x + x_inter)/2\n",
    "            return x\n",
    "\n",
    "        def decodeBlock4(self, x):\n",
    "            x = F.relu(self.convDecodBlock4start(x))\n",
    "            x = self.deconvDecodBlock4(x)\n",
    "            x = F.relu(self.convDecodBlock4end(x))\n",
    "            return x\n",
    "\n",
    "        def decodeBlock3(self, x):\n",
    "            x = F.relu(self.convDecodBlock3start(x))\n",
    "            x = self.deconvDecodBlock3(x)\n",
    "            x = F.relu(self.convDecodBlock3end(x))\n",
    "            return x\n",
    "\n",
    "        def decodeBlock2(self, x):\n",
    "            x = F.relu(self.convDecodBlock2start(x))\n",
    "            x = self.deconvDecodBlock2(x)\n",
    "            x = F.relu(self.convDecodBlock2end(x))\n",
    "            return x\n",
    "\n",
    "        def decodeBlock1(self, x):\n",
    "            x = F.relu(self.convDecodBlock1start(x))\n",
    "            x = self.deconvDecodBlock1(x)\n",
    "            x = F.relu(self.convDecodBlock1end(x))\n",
    "            return x\n",
    "        \n",
    "        x_start = F.relu(self.convstart(x))\n",
    "        x_start = self.pool(x_start)\n",
    "        \n",
    "        x_codeBlock1 = codeBlock1(self, x_start)\n",
    "        x_codeBlock2 = codeBlock2(self, x_codeBlock1)\n",
    "        x_codeBlock3 = codeBlock3(self, x_codeBlock2)\n",
    "        x_codeBlock4 = codeBlock4(self, x_codeBlock3)\n",
    "        \n",
    "        x_center1 = F.relu(self.convCenterdil1(x_codeBlock4))\n",
    "        x_center2 = F.relu(self.convCenterdil2(x_center1))\n",
    "        x_center3 = F.relu(self.convCenterdil4(x_center2))\n",
    "        x_center4 = F.relu(self.convCenterdil8(x_center3))\n",
    "        \n",
    "        x_center_final = (x_codeBlock4 + x_center1 + x_center2 + x_center3 + x_center4)/5\n",
    "        \n",
    "        x_decodeBlock4 = decodeBlock4(self, x_center_final)\n",
    "        x_decodeBlock3 = decodeBlock3(self, (x_decodeBlock4 + x_codeBlock3)/2)\n",
    "        x_decodeBlock2 = decodeBlock2(self, (x_decodeBlock3 + x_codeBlock2)/2)\n",
    "        x_decodeBlock1 = decodeBlock1(self, (x_decodeBlock2 + x_codeBlock1)/2)\n",
    "        \n",
    "        x_end = self.deconvDecodend(x_decodeBlock1)\n",
    "        x_end = F.relu(self.convDecoddil1end(x_end))\n",
    "        x_end = self.sigmoid(x_end)\n",
    "        \n",
    "        return(x_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class takes our input of size 400*400 and directly put it to size 256*256\n",
    "\n",
    "class FCN_DLinkNet_new(torch.nn.Module):\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(FCN_DLinkNet_new, self).__init__()\n",
    "        \n",
    "        # Encoding part\n",
    "        \n",
    "        self.convstart = torch.nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=57)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        \n",
    "        self.convEncodBlock1 = torch.nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock2start = torch.nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock2 = torch.nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock3start = torch.nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock3 = torch.nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock4start = torch.nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock4 = torch.nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Center part\n",
    "        \n",
    "        self.convCenterdil1 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1) #same as convEncodBlock4 but added for clarity\n",
    "        self.convCenterdil2 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=2, dilation=2)\n",
    "        self.convCenterdil4 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=4, dilation=4)\n",
    "        self.convCenterdil8 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=8, dilation=8)\n",
    "        \n",
    "        # Decoding part\n",
    "        \n",
    "        self.convDecodBlock4start = torch.nn.Conv2d(512, 128, kernel_size=1)\n",
    "        self.deconvDecodBlock4 = torch.nn.ConvTranspose2d(128, 128, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock4end = torch.nn.Conv2d(128, 256, kernel_size=1)\n",
    "        self.normback4 = torch.nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.convDecodBlock3start = torch.nn.Conv2d(256, 64, kernel_size=1)\n",
    "        self.deconvDecodBlock3 = torch.nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock3end = torch.nn.Conv2d(64, 128, kernel_size=1)\n",
    "        self.normback3 = torch.nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.convDecodBlock2start = torch.nn.Conv2d(128, 32, kernel_size=1)\n",
    "        self.deconvDecodBlock2 = torch.nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock2end = torch.nn.Conv2d(32, 64, kernel_size=1)\n",
    "        self.normback2 = torch.nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.convDecodBlock1start = torch.nn.Conv2d(64, 16, kernel_size=1)\n",
    "        self.deconvDecodBlock1 = torch.nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock1end = torch.nn.Conv2d(16, 64, kernel_size=1)\n",
    "        self.normback1 = torch.nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.deconvDecodend = torch.nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=57)\n",
    "        self.convDecoddil1end = torch.nn.Conv2d(32, 2, kernel_size=3, stride=1, padding=1, dilation=1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        def codeBlock1(self, x):\n",
    "            for i in range(0, 3):\n",
    "                x_inter = F.relu(self.convEncodBlock1(x))\n",
    "                x_inter = F.relu(self.convEncodBlock1(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def codeBlock2(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock2start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock2(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :64, :, :] = x\n",
    "            # Moyenne\n",
    "            x = new_x + x_inter\n",
    "            for i in range(0, 3):\n",
    "                x_inter = F.relu(self.convEncodBlock2(x))\n",
    "                x_inter = F.relu(self.convEncodBlock2(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def codeBlock3(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock3start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock3(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :128, :, :] = x\n",
    "            # Moyenne\n",
    "            x = new_x + x_inter\n",
    "            for i in range(0, 5):\n",
    "                x_inter = F.relu(self.convEncodBlock3(x))\n",
    "                x_inter = F.relu(self.convEncodBlock3(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def codeBlock4(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock4start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock4(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :256, :, :] = x\n",
    "            # Moyenne\n",
    "            x = new_x + x_inter\n",
    "            for i in range(0, 2):\n",
    "                x_inter = F.relu(self.convEncodBlock4(x))\n",
    "                x_inter = F.relu(self.convEncodBlock4(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def decodeBlock4(self, x):\n",
    "            x = F.relu(self.convDecodBlock4start(x))\n",
    "            x = self.deconvDecodBlock4(x)\n",
    "            x = F.relu(self.convDecodBlock4end(x))\n",
    "            x = self.normback4(x)\n",
    "            return x\n",
    "\n",
    "        def decodeBlock3(self, x):\n",
    "            x = F.relu(self.convDecodBlock3start(x))\n",
    "            x = self.deconvDecodBlock3(x)\n",
    "            x = F.relu(self.convDecodBlock3end(x))\n",
    "            x = self.normback3(x)\n",
    "            return x\n",
    "\n",
    "        def decodeBlock2(self, x):\n",
    "            x = F.relu(self.convDecodBlock2start(x))\n",
    "            x = self.deconvDecodBlock2(x)\n",
    "            x = F.relu(self.convDecodBlock2end(x))\n",
    "            x = self.normback2(x)\n",
    "            return x\n",
    "\n",
    "        def decodeBlock1(self, x):\n",
    "            x = F.relu(self.convDecodBlock1start(x))\n",
    "            x = self.deconvDecodBlock1(x)\n",
    "            x = F.relu(self.convDecodBlock1end(x))\n",
    "            x = self.normback1(x)\n",
    "            return x\n",
    "        \n",
    "        x_start = F.relu(self.convstart(x))\n",
    "        \n",
    "        x_codeBlock1 = codeBlock1(self, x_start)\n",
    "        x_codeBlock2 = codeBlock2(self, x_codeBlock1)\n",
    "        x_codeBlock3 = codeBlock3(self, x_codeBlock2)\n",
    "        x_codeBlock4 = codeBlock4(self, x_codeBlock3)\n",
    "        \n",
    "        x_center1 = F.relu(self.convCenterdil1(x_codeBlock4))\n",
    "        x_center2 = F.relu(self.convCenterdil2(x_center1))\n",
    "        x_center3 = F.relu(self.convCenterdil4(x_center2))\n",
    "        x_center4 = F.relu(self.convCenterdil8(x_center3))\n",
    "        \n",
    "        x_center_final = x_codeBlock4 + x_center1 + x_center2 + x_center3 + x_center4\n",
    "        \n",
    "        x_decodeBlock4 = decodeBlock4(self, x_center_final)\n",
    "        x_decodeBlock3 = decodeBlock3(self, x_decodeBlock4 + x_codeBlock3)\n",
    "        x_decodeBlock2 = decodeBlock2(self, x_decodeBlock3 + x_codeBlock2)\n",
    "        x_decodeBlock1 = decodeBlock1(self, x_decodeBlock2 + x_codeBlock1)\n",
    "        \n",
    "        x_end = self.deconvDecodend(x_decodeBlock1)\n",
    "        x_end = F.relu(self.convDecoddil1end(x_end))\n",
    "        x_end = self.sigmoid(x_end)\n",
    "        \n",
    "        return(x_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class takes our input of size 400*400 and directly put it to size 256*256\n",
    "\n",
    "class FCN_DLinkNet_direct(torch.nn.Module):\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(FCN_DLinkNet_direct, self).__init__()\n",
    "        \n",
    "        # Encoding part\n",
    "        \n",
    "        self.convstart = torch.nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.convEncodBlock1 = torch.nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock2start = torch.nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock2 = torch.nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock3start = torch.nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock3 = torch.nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.convEncodBlock4start = torch.nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.convEncodBlock4 = torch.nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Center part\n",
    "        \n",
    "        self.convCenterdil1 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1) #same as convEncodBlock4 but added for clarity\n",
    "        self.convCenterdil2 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=2, dilation=2)\n",
    "        self.convCenterdil4 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=4, dilation=4)\n",
    "        self.convCenterdil8 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=8, dilation=8)\n",
    "        \n",
    "        # Decoding part\n",
    "        \n",
    "        self.convDecodBlock4start = torch.nn.Conv2d(512, 128, kernel_size=1)\n",
    "        self.deconvDecodBlock4 = torch.nn.ConvTranspose2d(128, 128, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock4end = torch.nn.Conv2d(128, 256, kernel_size=1)\n",
    "        \n",
    "        self.convDecodBlock3start = torch.nn.Conv2d(256, 64, kernel_size=1)\n",
    "        self.deconvDecodBlock3 = torch.nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock3end = torch.nn.Conv2d(64, 128, kernel_size=1)\n",
    "        \n",
    "        self.convDecodBlock2start = torch.nn.Conv2d(128, 32, kernel_size=1)\n",
    "        self.deconvDecodBlock2 = torch.nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock2end = torch.nn.Conv2d(32, 64, kernel_size=1)\n",
    "        \n",
    "        self.convDecodBlock1start = torch.nn.Conv2d(64, 16, kernel_size=1)\n",
    "        self.deconvDecodBlock1 = torch.nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convDecodBlock1end = torch.nn.Conv2d(16, 64, kernel_size=1)\n",
    "        \n",
    "        self.deconvDecodend = torch.nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.convDecoddil1end = torch.nn.Conv2d(32, 2, kernel_size=3, stride=2, padding=2, dilation=2)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        def codeBlock1(self, x):\n",
    "            for i in range(0, 3):\n",
    "                x_inter = F.relu(self.convEncodBlock1(x))\n",
    "                x_inter = F.relu(self.convEncodBlock1(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def codeBlock2(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock2start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock2(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :64, :, :] = x\n",
    "            # Moyenne\n",
    "            x = new_x + x_inter\n",
    "            for i in range(0, 3):\n",
    "                x_inter = F.relu(self.convEncodBlock2(x))\n",
    "                x_inter = F.relu(self.convEncodBlock2(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def codeBlock3(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock3start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock3(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :128, :, :] = x\n",
    "            # Moyenne\n",
    "            x = new_x + x_inter\n",
    "            for i in range(0, 5):\n",
    "                x_inter = F.relu(self.convEncodBlock3(x))\n",
    "                x_inter = F.relu(self.convEncodBlock3(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def codeBlock4(self, x):\n",
    "            x = self.pool(x)\n",
    "            x_inter = F.relu(self.convEncodBlock4start(x))\n",
    "            x_inter = F.relu(self.convEncodBlock4(x_inter))\n",
    "            new_x = torch.zeros(x_inter.shape)\n",
    "            new_x[:, :256, :, :] = x\n",
    "            # Moyenne\n",
    "            x = new_x + x_inter\n",
    "            for i in range(0, 2):\n",
    "                x_inter = F.relu(self.convEncodBlock4(x))\n",
    "                x_inter = F.relu(self.convEncodBlock4(x_inter))\n",
    "                # Moyenne\n",
    "                x = x + x_inter\n",
    "            return x\n",
    "\n",
    "        def decodeBlock4(self, x):\n",
    "            x = F.relu(self.convDecodBlock4start(x))\n",
    "            x = self.deconvDecodBlock4(x)\n",
    "            x = F.relu(self.convDecodBlock4end(x))\n",
    "            return x\n",
    "\n",
    "        def decodeBlock3(self, x):\n",
    "            x = F.relu(self.convDecodBlock3start(x))\n",
    "            x = self.deconvDecodBlock3(x)\n",
    "            x = F.relu(self.convDecodBlock3end(x))\n",
    "            return x\n",
    "\n",
    "        def decodeBlock2(self, x):\n",
    "            x = F.relu(self.convDecodBlock2start(x))\n",
    "            x = self.deconvDecodBlock2(x)\n",
    "            x = F.relu(self.convDecodBlock2end(x))\n",
    "            return x\n",
    "\n",
    "        def decodeBlock1(self, x):\n",
    "            x = F.relu(self.convDecodBlock1start(x))\n",
    "            x = self.deconvDecodBlock1(x)\n",
    "            x = F.relu(self.convDecodBlock1end(x))\n",
    "            return x\n",
    "        \n",
    "        x_start = F.relu(self.convstart(x))\n",
    "        \n",
    "        x_codeBlock1 = codeBlock1(self, x_start)\n",
    "        x_codeBlock2 = codeBlock2(self, x_codeBlock1)\n",
    "        x_codeBlock3 = codeBlock3(self, x_codeBlock2)\n",
    "        x_codeBlock4 = codeBlock4(self, x_codeBlock3)\n",
    "        \n",
    "        x_center1 = F.relu(self.convCenterdil1(x_codeBlock4))\n",
    "        x_center2 = F.relu(self.convCenterdil2(x_center1))\n",
    "        x_center3 = F.relu(self.convCenterdil4(x_center2))\n",
    "        x_center4 = F.relu(self.convCenterdil8(x_center3))\n",
    "        \n",
    "        x_center_final = x_codeBlock4 + x_center1 + x_center2 + x_center3 + x_center4\n",
    "        \n",
    "        x_decodeBlock4 = decodeBlock4(self, x_center_final)\n",
    "        x_decodeBlock3 = decodeBlock3(self, x_decodeBlock4 + x_codeBlock3)\n",
    "        x_decodeBlock2 = decodeBlock2(self, x_decodeBlock3 + x_codeBlock2)\n",
    "        x_decodeBlock1 = decodeBlock1(self, x_decodeBlock2 + x_codeBlock1)\n",
    "        \n",
    "        x_end = self.deconvDecodend(x_decodeBlock1)\n",
    "        x_end = F.relu(self.convDecoddil1end(x_end))\n",
    "        x_end = self.sigmoid(x_end)\n",
    "        \n",
    "        return(x_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model optimized with adam and cross entropy will converge to all-black images every time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "end_train = 15 # normally = 90\n",
    "end_validation = 20 # normally = 100\n",
    "\n",
    "# Loading a set of 100 training images\n",
    "root_dir = \"training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = min(100, len(files)) # Load maximum 100 images\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = np.array([load_image(image_dir + files[i]) for i in range(n)]).swapaxes(1,3).swapaxes(2,3)\n",
    "print(np.shape(imgs))\n",
    "\n",
    "train_input = imgs[0:end_train] #normally = 0:90\n",
    "validation_input = imgs[end_train:end_validation] #normally = 90:100\n",
    "\n",
    "image_dir = root_dir + \"groundtruth/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = min(100, len(files)) # Load maximum 100 images\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "grounds = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "print(np.shape(grounds))\n",
    "\n",
    "train_target = grounds[0:end_train] #normally = 0:90\n",
    "validation_target = grounds[end_train:end_validation] #normally = 90:100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop images to their 256*256 counterparts\n",
    "cropped_imgs = []\n",
    "cropped_targets = []\n",
    "\n",
    "for i in range(end_validation):\n",
    "    cropped_img, k, l = img_rnd_crop(imgs[i], 256, 256)\n",
    "    cropped_target, _, _ = img_rnd_crop(grounds[i], 256, 256, k, l)\n",
    "    cropped_imgs.append(cropped_img)\n",
    "    cropped_targets.append(cropped_target)\n",
    "    \n",
    "train_input = cropped_imgs[0:end_train] #normally = 0:90\n",
    "validation_input = cropped_imgs[end_train:end_validation] #normally = 90:100\n",
    "\n",
    "\n",
    "train_target = cropped_targets[0:end_train] #normally = 0:90\n",
    "validation_target = cropped_targets[end_train:end_validation] #normally = 90:100\n",
    "\n",
    "display(np.shape(train_input))\n",
    "display(np.shape(validation_input))\n",
    "display(np.shape(train_target))\n",
    "display(np.shape(validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep 10 images from this set as a validation set.\n",
    "To shorten the computationnal time we will use a smaller amount of images to do tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the model, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We will optimize the cross-entropy loss using adam algorithm\n",
    "net = FCN_DLinkNet_direct()\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "optimizer = optim.SGD(net.parameters(), lr=3.75e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNet(net, n_epochs):\n",
    "    \n",
    "    #Time for printing\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    #Loop for n_epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for index in range(np.shape(train_input)[0]):\n",
    "            \n",
    "            input_image = Variable(torch.tensor(train_input[index], requires_grad=True).unsqueeze(0))\n",
    "            target_image = Variable(torch.tensor(train_target[index], dtype=torch.long).unsqueeze(0))\n",
    "            \n",
    "            #Set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Forward pass, backward pass, optimize\n",
    "            outputs = net(input_image)\n",
    "            loss = loss_function(outputs, target_image)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Print statistics\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            print(\"Epoch\", epoch, \", image\", index, \", image loss:\", loss.item(), \", time elapsed:\", time.time() - training_start_time)\n",
    "            \n",
    "        #At the end of the epoch, do a pass on the validation set\n",
    "        total_val_loss = 0\n",
    "        for index in range(np.shape(validation_input)[0]):\n",
    "            \n",
    "            input_image = Variable(torch.tensor(validation_input[index], requires_grad=True).unsqueeze(0))\n",
    "            target_image = Variable(torch.tensor(validation_target[index], dtype=torch.long).unsqueeze(0))\n",
    "            \n",
    "            #Forward pass\n",
    "            val_outputs = net(input_image)\n",
    "            val_loss = loss_function(val_outputs, target_image)\n",
    "            total_val_loss += val_loss.item()\n",
    "            \n",
    "        print(\"Validation loss for epoch\", epoch, \":\", total_val_loss/np.shape(validation_input)[0])\n",
    "        \n",
    "    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainNet(net, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.tensor(validation_input[0]).unsqueeze(0)\n",
    "target_image = torch.tensor(validation_target[0]).unsqueeze(0)\n",
    "           \n",
    "#Forward pass\n",
    "val_output = net(input_image)\n",
    "output_image = val_output[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(target_image.squeeze(0), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(output_image.detach().numpy(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
