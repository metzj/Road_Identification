{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Exploratory data analysis strongly inspired by 'https://www.kaggle.com/ekami66/detailed-exploratory-data-analysis-with-python'. The steps to procede are:\n",
    "-Data Exploration\n",
    "--Purely visual description (DONE)\n",
    "--Transform images into scalar values (DONE)\n",
    "--Find Correlations (TO DO)\n",
    "\n",
    "-Data Cleaning\n",
    "--Remove/Adapt Features (TO DO)\n",
    "--Test Correlations (TO DO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Description"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We first do a quick visual description of the training data set. There are two sets of 90 different images. The first set corresponds to the satellite images of what seems to be a city. These images are colored so when transforming those into scalars, there will be three different values (RGB ?). The second set correspond to the black and white version of the first set with white where there is road and black everywhere else.\n",
    "\n",
    "The distinct elements that can be found in the pictures are houses, trees, buildings, parking lots, stadiums, train tracks, wastelands, highway and water. The detail analysis can be find in the file 'VisualExploratoryDataAnalysis.xlsx'.\n",
    "\n",
    "The first conclusions that can be drawn from this analysis is that the pictures are taken in a dense urban area. A high percentage of the picture have houses (89%), larger buildings (36%) or even parking lots (39%). Moreover, it is clear that certain elements will make the process of detecting the road harder: trees that covers parts of or even large portion of the road are largely represented (91%), parking lots that have a road inside them, pavement is omnipresent, large portion of non-road surface (water: 4%, stadium-like structures: 9%, buildings: 36%), certain portion of wasteland (5%) that have the same colour than the roads, and last but not least the train tracks (12%) that are road-like structures that are not roads and highway portion (5%) that are road-like structures that are indeed much larger roads!\n",
    "\n",
    "From this first quick analysis we can find three different groups:\n",
    " -The group of pictures presenting only houses and trees: Group 1 = 45%;\n",
    " -The group of pictures preventing houses, trees, larger building and parking lots: Group 2 = 14%;\n",
    " -The group of very peculiar pictures that don't correspond at all with the others: Group 0 = 8%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform images into scalar values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Before trying to approach the data analysis using correlation functions with first need to convert our image from a picture representation to a RGB-scalar representation. We do this with the help of the segment_aerial_image.ipynb notebook given with the project description.\n",
    "\n",
    "Whether we have to use the three different values separatly or do a mean is still to be determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - np.min(img)\n",
    "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "    return rimg\n",
    "\n",
    "# Concatenate an image and its groundtruth\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = np.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 images\n",
      "satImage_001.png\n"
     ]
    }
   ],
   "source": [
    "# Loaded a set of images\n",
    "root_dir = \"training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = min(100, len(files)) # Load maximum 100 images\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 400, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "rimgs = img_float_to_uint8(imgs)\n",
    "print(np.shape(rimgs))\n",
    "\n",
    "# rimgs contains 100 picture of size 400*400 pixels in RGB values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Correlations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
